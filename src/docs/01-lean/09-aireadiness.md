# AI Readiness Canvas - ASCII Wireframe & Sample Content

**Template:** Incremental Excellence AI Readiness Canvas  
**Use Case Example:** SaaS Startup - Customer Support Automation with AI  
**Status:** Production-Ready Sample  
**Author:** Peter Scheffer  
**License:** CC BY-SA 4.0

---

## Full Canvas Wireframe (9-Box Layout)

```
┌────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                  AI READINESS CANVAS                                                            │
│                                        Assess Organizational Preparedness for AI Implementation                                 │
│                                                                                                                                 │
│                                    Source: incrementalexcellence.com/ai-readiness-canvas                                       │
│                                              © 2025 Peter Scheffer | CC BY-SA 4.0                                              │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                                                 │
│                                         THE STRATEGIC IMPERATIVE — WHY?                                                         │
│                                         ════════════════════════════════                                                        │
│                                                                                                                                 │
│  ┌───────────────────────────────────────────────────┬──────────────────────────────────────────────────────────────────┐    │
│  │  #1 AI VISION & BUSINESS OUTCOMES            [✨]  │  #3 KEY USE CASES & PRIORITISATION                          [✨]  │    │
│  │  ─────────────────────────────────────────────    │  ─────────────────────────────────────────────────                │    │
│  │                                                    │                                                                   │    │
│  │  Define the "North Star" to explain:              │  Which high-value AI initiatives and use cases will we            │    │
│  │  Why are we doing this?                           │  prioritise?                                                      │    │
│  │                                                    │                                                                   │    │
│  │  VISION STATEMENT:                                │  PRIORITISED USE CASES (Impact × Feasibility × Viability):        │    │
│  │  Transform customer support from reactive cost    │                                                                   │    │
│  │  center to proactive revenue driver through AI-   │  HIGH PRIORITY (Q1-Q2 2026):                                      │    │
│  │  powered automation and insights.                 │  ✓ 1. AI chatbot for Tier-1 support (FAQ, billing, routing)      │    │
│  │                                                    │       Impact: ★★★★★ (70% ticket deflection)                      │    │
│  │  BUSINESS OUTCOMES:                               │       Feasibility: ★★★★☆ (existing training data)                │    │
│  │  • Reduce support costs by 40% within 12 months   │       Viability: ★★★★★ (ROI <6 months)                           │    │
│  │  • Improve customer satisfaction (CSAT) from      │                                                                   │    │
│  │    78% to 92%                                     │  ✓ 2. Sentiment analysis on support tickets                       │    │
│  │  • Scale support capacity 3x without adding       │       Impact: ★★★★☆ (identify escalation risks early)            │    │
│  │    headcount                                      │       Feasibility: ★★★★★ (off-the-shelf models)                  │    │
│  │  • Unlock $2M+ annual revenue from proactive      │       Viability: ★★★★☆ (low cost, quick win)                     │    │
│  │    upsell insights                                │                                                                   │    │
│  │  • Enter new market segment (SMB) with self-      │  MEDIUM PRIORITY (Q3-Q4 2026):                                    │    │
│  │    service AI support                             │  • 3. AI-powered knowledge base auto-generation                   │    │
│  │                                                    │       Impact: ★★★★☆ (reduce docs effort 60%)                     │    │
│  │  COMPETITIVE ADVANTAGE:                           │       Feasibility: ★★★☆☆ (requires RAG implementation)           │    │
│  │  First in our vertical to offer instant 24/7     │       Viability: ★★★☆☆ (longer ROI timeline)                     │    │
│  │  multilingual support with human-level accuracy.  │                                                                   │    │
│  │  Differentiate on "AI-first CX" positioning.      │  • 4. Predictive churn detection from support patterns           │    │
│  │                                                    │       Impact: ★★★★★ (prevent $500K annual churn)                 │    │
│  │  TRANSFORMATIONAL OPPORTUNITIES:                  │       Feasibility: ★★☆☆☆ (complex ML model, data prep)           │    │
│  │  • Shift brand positioning from "tool" to         │       Viability: ★★★★☆ (high value, higher risk)                 │    │
│  │    "intelligent partner"                          │                                                                   │    │
│  │  • Launch AI-as-a-Service white-label product     │  LOW PRIORITY (2027+):                                            │    │
│  │    for partners                                   │  • 5. Generative AI for automated response drafts (human-        │    │
│  │  • Create data flywheel: more customers →         │       in-loop)                                                    │    │
│  │    better AI → better product → more customers    │  • 6. Voice AI for phone support automation                       │    │
│  │                                                    │                                                                   │    │
│  │  TIMELINE: 18-month roadmap (Q1 2026-Q2 2027)     │  EVALUATION CRITERIA:                                             │    │
│  │                                                    │  • Impact: Business value, customer benefit, competitive edge     │    │
│  │                                                    │  • Feasibility: Tech readiness, data availability, talent         │    │
│  │                                                    │  • Viability: ROI, cost, time-to-value, risk                      │    │
│  │                                                    │                                                                   │    │
│  └───────────────────────────────────────────────────┴──────────────────────────────────────────────────────────────────┘    │
│                                                                                                                                 │
│                                         FOUNDATIONAL CAPABILITIES — HOW?                                                        │
│                                         ════════════════════════════════════                                                    │
│                                                                                                                                 │
│  ┌──────────────────────────────────────┬───────────────────────────────────────┬────────────────────────────────────────┐    │
│  │  #4 DATA STRATEGY & ASSETS      [✨] │  #5 AI PLATFORM & TECHNOLOGY     [✨] │  #6 PEOPLE, SKILLS & CULTURE      [✨] │    │
│  │  ─────────────────────────────       │  ─────────────────────────────        │  ─────────────────────────────         │    │
│  │                                       │                                        │                                         │    │
│  │  What is our strategy for acquiring,  │  Which technology shall we use to     │  How will we build the right            │    │
│  │  managing, and utilising data assets? │  build, deploy, and run AI solutions? │  culture, skills, talent & mindset?     │    │
│  │                                       │                                        │                                         │    │
│  │  INTERNAL DATA SOURCES:               │  TECH STACK DECISIONS:                │  CURRENT STATE (Talent):                │    │
│  │  ✓ 2M+ support tickets (5 years)      │  • Cloud: AWS (primary), Azure (DR)   │  • 0 ML engineers (hiring 2 in Q1)      │    │
│  │  ✓ 50K+ customer profiles & history   │  • LLM: OpenAI GPT-4o, Anthropic      │  • 1 data scientist (part-time)         │    │
│  │  ✓ 500K+ product usage logs/day       │    Claude (fallback)                  │  • 3 product engineers (upskilling)     │    │
│  │  ✓ CRM data (Salesforce, 100K+ rec)   │  • Vector DB: Pinecone for RAG        │  • 12 support agents (AI trainers)      │    │
│  │  ✓ NPS surveys (quarterly, 3 years)   │  • Orchestration: LangChain, custom   │  • 0 AI ethicist (consultant TBD)       │    │
│  │                                       │  • Monitoring: Datadog, custom logs   │                                         │    │
│  │  EXTERNAL DATA SOURCES:               │                                        │  HIRING ROADMAP (12 months):            │    │
│  │  • Industry benchmarks (Zendesk)      │  BUILD vs BUY vs PARTNER:             │  • Q1: 2 ML engineers, 1 AI PM          │    │
│  │  • Open datasets for model training   │  BUILD: Custom chatbot orchestration,  │  • Q2: 1 MLOps engineer                 │    │
│  │  • Third-party enrichment (Clearbit)  │         fine-tuned routing model       │  • Q3: 1 AI strategist                  │    │
│  │                                       │  BUY:   OpenAI API, Pinecone           │  • Q4: 1 conversational designer        │    │
│  │  DATA QUALITY & GOVERNANCE:           │  PARTNER: Zendesk AI integration,     │                                         │    │
│  │  • 85% of tickets have clean labels   │          AWS managed services          │  SKILLS DEVELOPMENT:                    │    │
│  │  • PII scrubbing automated (GDPR)     │                                        │  • All PMs: 2-day AI fluency workshop   │    │
│  │  • Data lineage tracked in dbt        │  AI LIFECYCLE:                         │  • Engineers: Coursera ML cert (Q1-Q2)  │    │
│  │  • Annual audit by InfoSec team       │  Experiment → Staging → Production:   │  • Support: "AI trainer" role created   │    │
│  │                                       │  • Dev: Jupyter, local models          │  • Leadership: GenAI executive program  │    │
│  │  DATA ACCESSIBILITY:                  │  • Staging: AWS SageMaker, A/B tests   │                                         │    │
│  │  • Data warehouse: Snowflake          │  • Prod: Containerized (ECS), auto-    │  CULTURE SHIFTS:                        │    │
│  │  • API access: REST, GraphQL          │    scaled                              │  • From "AI will replace us" to "AI     │    │
│  │  • Self-service: Looker dashboards    │  • Rollback: Feature flags, blue/green │    augments us"                         │    │
│  │  • Compliance: SOC 2, GDPR ready      │                                        │  • Hackathons: Monthly AI experiments   │    │
│  │                                       │  OPERATING MODEL:                      │  • Transparency: Weekly AI town halls   │    │
│  │  AI FLYWHEEL DESIGN:                  │  • Centralized AI platform team (5)    │  • Incentives: AI innovation bonuses    │    │
│  │  Products generate data →             │  • Hub-and-spoke: Product teams own    │  • Career paths: IC → AI specialist     │    │
│  │  Improves AI →                        │    domain use cases, platform team     │                                         │    │
│  │  Improves product →                   │    provides infra/tooling              │  CHANGE MANAGEMENT:                     │    │
│  │  More customers →                     │  • Decentralized experimentation,      │  • 1:1s: Address AI anxiety (agents)    │    │
│  │  More data                            │    centralized governance              │  • Reskilling: Agents → AI trainers →   │    │
│  │                                       │                                        │    CX strategists                       │    │
│  │  Example: Chatbot interactions        │  DEPLOYMENT STRATEGY:                  │  • Pilot team: 3 "AI champions" embed   │    │
│  │  improve model accuracy weekly        │  Phased rollout: 10% → 50% → 100%     │  • Metrics: Track AI fluency scores     │    │
│  │                                       │  of traffic over 8 weeks               │                                         │    │
│  └──────────────────────────────────────┴───────────────────────────────────────┴────────────────────────────────────────┘    │
│                                                                                                                                 │
│                                         EXECUTION & OPERATIONS — WHAT?                                                          │
│                                         ══════════════════════════════════                                                      │
│                                                                                                                                 │
│  ┌───────────────────────────────────────────────────┐                                                                         │
│  │  #2 AI VALUE PROPOSITION                     [✨] │                                                                         │
│  │  ─────────────────────────────────────────────    │                                                                         │
│  │                                                    │                                                                         │
│  │  How will AI create new value for our customers   │                                                                         │
│  │  and the business?                                │                                                                         │
│  │                                                    │                                                                         │
│  │  FOR CUSTOMERS:                                   │                                                                         │
│  │  • Instant answers 24/7 (no wait times)           │                                                                         │
│  │  • Multilingual support (10 languages, auto)      │                                                                         │
│  │  • Consistent quality (90%+ accuracy vs 78% today)│                                                                         │
│  │  • Personalized recommendations based on history  │                                                                         │
│  │  • Proactive outreach (AI detects issues early)   │                                                                         │
│  │                                                    │                                                                         │
│  │  FOR THE BUSINESS:                                │                                                                         │
│  │  • $800K annual cost savings (headcount, tools)   │                                                                         │
│  │  • 3x capacity: Handle 10K→30K tickets/month      │                                                                         │
│  │  • $2M revenue from AI-detected upsell triggers   │                                                                         │
│  │  • Enter SMB market (new $5M ARR opportunity)     │                                                                         │
│  │  • Competitive moat: AI-first positioning         │                                                                         │
│  │                                                    │                                                                         │
│  │  NEW PRODUCTS/SERVICES:                           │                                                                         │
│  │  • AI Support API: White-label for partners ($200/│                                                                         │
│  │    mo per partner)                                │                                                                         │
│  │  • Premium tier: "AI Concierge" (+$50/user/mo)    │                                                                         │
│  │  • Data insights dashboard for enterprise clients │                                                                         │
│  │                                                    │                                                                         │
│  │  UNIQUE DIFFERENTIATION:                          │                                                                         │
│  │  • Only vertical SaaS with industry-trained LLM   │                                                                         │
│  │  • "AI Trust Score" transparency (explainability) │                                                                         │
│  │  • Human-in-loop for complex issues (hybrid model)│                                                                         │
│  │                                                    │                                                                         │
│  │  CUSTOMER PROBLEM SOLVED:                         │                                                                         │
│  │  Pain: "I can't get help outside business hours"  │                                                                         │
│  │  Solution: AI chatbot handles 90% of Tier-1 24/7  │                                                                         │
│  │                                                    │                                                                         │
│  │  Pain: "Support quality varies by agent"          │                                                                         │
│  │  Solution: AI ensures consistent, accurate answers│                                                                         │
│  │                                                    │                                                                         │
│  └───────────────────────────────────────────────────┘                                                                         │
│                                                                                                                                 │
│  ┌──────────────────────────────────────┬───────────────────────────────────────┬────────────────────────────────────────┐    │
│  │  #7 GOVERNANCE & RESPONSIBLE AI [✨] │  #8 COSTS & FINANCIAL MGMT       [✨] │  #9 SUCCESS METRICS & ROI         [✨] │    │
│  │  ─────────────────────────────       │  ─────────────────────────────        │  ─────────────────────────────         │    │
│  │                                       │                                        │                                         │    │
│  │  How will we minimise ethical and     │  How will we plan, measure, and       │  How will we measure success to ensure  │    │
│  │  compliance related risks and issues? │  optimise the costs associated with   │  AI initiatives deliver value and       │    │
│  │                                       │  AI?                                   │  justify investment?                    │    │
│  │  ACCOUNTABILITY:                      │                                        │                                         │    │
│  │  • AI Steering Committee (exec-level) │  COST DRIVERS:                        │  BUSINESS KPIs (Primary):               │    │
│  │    meets monthly                      │  • LLM API calls: $15K/mo (70%)       │  • Support cost per ticket: $12→$5      │    │
│  │  • AI Ethics Officer: Head of Product │  • Compute (training, inference):     │  • Ticket deflection rate: 0%→70%       │    │
│  │    (interim), consultant in Q2        │    $5K/mo (20%)                       │  • Customer satisfaction (CSAT):        │    │
│  │  • Data Privacy Lead: Legal counsel   │  • Storage (vectors, logs): $1K/mo    │    78%→92%                              │    │
│  │  • Model owners: Product teams        │  • Talent: $500K/yr (salaries)        │  • Support team capacity: 10K→30K       │    │
│  │                                       │  • Tooling/licenses: $3K/mo           │    tickets/mo (no new hires)            │    │
│  │  RESPONSIBLE AI FRAMEWORK:            │  • Fine-tuning: $10K one-time         │  • Time to resolution: 4hr→15min        │    │
│  │  • Fairness: Bias audits quarterly    │                                        │                                         │    │
│  │  • Transparency: "Why this answer?"   │  TOTAL YEAR 1:                        │  FINANCIAL ROI (12 months):             │    │
│  │    feature for chatbot                │  • Setup: $50K (infra, training)      │  • Cost savings: $800K (headcount,      │    │
│  │  • Privacy: PII scrubbing, on-device  │  • Ongoing: $24K/mo × 12 = $288K      │    tools)                               │    │
│  │    inference for sensitive data       │  • Talent: $500K                      │  • New revenue: $2M (upsell insights,   │    │
│  │  • Safety: Human-in-loop for high-    │  • TOTAL: $838K                       │    SMB segment)                         │    │
│  │    stakes decisions (billing, refunds)│                                        │  • Investment: $838K                    │    │
│  │  • Accountability: Audit logs, version│  ZIG-ZAG COST PATTERN:                │  • NET GAIN: $1.96M                     │    │
│  │    control for prompts                │  • Spike: Launch month (3x training)  │  • ROI: 234% (payback <6 months)        │    │
│  │                                       │  • Drop: Optimization in month 6       │                                         │    │
│  │  RISKS & MITIGATION:                  │  • Plateau: Efficient inference        │  NON-FINANCIAL METRICS:                 │    │
│  │  ⚠ Bias: Monthly fairness reports     │                                        │  • Employee satisfaction: Track AI      │    │
│  │    (gender, language, sentiment)      │  COMPUTE OPTIMIZATION:                │    tool NPS (target >8/10)              │    │
│  │  ⚠ Hallucinations: Confidence scores, │  • Caching: 40% cost reduction         │  • Brand perception: "AI-first CX"      │    │
│  │    fallback to human if <80%          │  • Model distillation: Switch to      │    positioning awareness (surveys)      │    │
│  │  ⚠ Prompt injection: Input validation,│    smaller models for simple tasks    │  • Innovation velocity: AI experiments  │    │
│  │    rate limiting                      │  • Batch inference: Off-peak hours    │    shipped per quarter (target: 3)      │    │
│  │  ⚠ Data leakage: Encrypted storage,   │  • Right-size compute: GPU only for   │                                         │    │
│  │    access control (RBAC)              │    training, CPU for inference        │  3Es FRAMEWORK:                         │    │
│  │                                       │                                        │  • Efficiency: Cost per ticket ↓58%     │    │
│  │  COMPLIANCE:                          │  FINOPS FOR AI:                        │  • Effectiveness: CSAT score ↑18%       │    │
│  │  • GDPR: Right to explanation, data   │  • Cost allocation by use case        │  • User Experience: Wait time ↓94%      │    │
│  │    portability                        │  • Budget alerts at 80% threshold     │                                         │    │
│  │  • EU AI Act: High-risk classification│  • Monthly cost review with Product   │  POST-DEPLOYMENT TRACKING:              │    │
│  │    (customer-facing), transparency    │  • ROI tracking per initiative        │  • Weekly dashboards (Looker)           │    │
│  │    obligations                        │                                        │  • Monthly business reviews             │    │
│  │  • SOC 2: Audit logs, incident resp.  │  TCO (3 years):                       │  • Quarterly model retraining & audits  │    │
│  │  • Industry standards: ISO 42001      │  • Year 1: $838K                      │  • Annual strategic review              │    │
│  │    (AI management system)             │  • Year 2: $400K (optimized)          │                                         │    │
│  │                                       │  • Year 3: $350K (mature)             │  JUSTIFICATION:                         │    │
│  │  HUMAN-IN-LOOP:                       │  • TOTAL: $1.59M                      │  "For every $1 invested in AI, we       │    │
│  │  All refunds >$500 require human OK   │  • Value created: $5M+ (3yr ROI 314%) │  generate $2.34 in value within 12      │    │
│  │  Escalation path always available     │                                        │  months, with 70% cost efficiency and   │    │
│  │  Weekly agent review of AI decisions  │                                        │  18% customer satisfaction improvement."│    │
│  │                                       │                                        │                                         │    │
│  └──────────────────────────────────────┴───────────────────────────────────────┴────────────────────────────────────────┘    │
│                                                                                                                                 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

                                        Incremental Excellence | © 2025 Peter Scheffer | CC BY-SA 4.0
```

---

## Condensed View (9 Sections Summary)

```
┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                   AI READINESS CANVAS                                             │
│                          SaaS Startup - Customer Support Automation with AI                       │
├──────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                                   │
│  WHY? — THE STRATEGIC IMPERATIVE                                                                 │
│  ────────────────────────────────                                                                │
│                                                                                                   │
│  #1 AI VISION & OUTCOMES                      #3 KEY USE CASES & PRIORITISATION                  │
│  Transform support from cost center to        1. AI chatbot for Tier-1 (Q1-Q2) ★★★★★             │
│  revenue driver. Goals: -40% costs, +18%      2. Sentiment analysis (Q1-Q2) ★★★★☆                 │
│  CSAT, 3x capacity, $2M+ new revenue.         3. Knowledge base auto-gen (Q3-Q4) ★★★☆☆            │
│  Competitive edge: 24/7 multilingual AI.      4. Churn prediction (Q3-Q4) ★★★★☆                   │
│                                                5. Voice AI (2027+) - future                       │
│                                                                                                   │
│  HOW? — FOUNDATIONAL CAPABILITIES                                                                │
│  ─────────────────────────────────                                                               │
│                                                                                                   │
│  #4 DATA STRATEGY & ASSETS           #5 AI PLATFORM & TECH           #6 PEOPLE, SKILLS & CULTURE │
│  • 2M+ support tickets (5yrs)         • AWS + Azure (cloud)           • Hire: 2 ML engineers (Q1) │
│  • 50K customer profiles              • OpenAI GPT-4o + Claude        • Upskill: 3 PMs, 12 agents│
│  • 500K logs/day, CRM, NPS            • Pinecone (vector DB)          • Culture: AI augments, not│
│  • Data quality: 85% clean            • Hub-and-spoke model           •   replaces (town halls)  │
│  • AI flywheel: Data → AI → Product   • Build (chatbot) + Buy (LLM)  • Change mgmt: Reskilling  │
│                                                                                                   │
│  WHAT? — EXECUTION & OPERATIONS                                                                  │
│  ───────────────────────────────                                                                 │
│                                                                                                   │
│  #2 AI VALUE PROPOSITION                                                                         │
│  Customers: 24/7 instant answers, multilingual, 90%+ accuracy, personalized                      │
│  Business: $800K savings, 3x capacity, $2M upsell revenue, enter SMB market                      │
│  New products: AI Support API, "AI Concierge" premium tier                                       │
│                                                                                                   │
│  #7 GOVERNANCE & RESPONSIBLE AI     #8 COSTS & FINANCIAL MGMT      #9 SUCCESS METRICS & ROI      │
│  • AI Steering Committee (monthly)   • Year 1 total: $838K            • Cost per ticket: $12→$5   │
│  • Ethics: Fairness audits, PII      • LLM API: $15K/mo (70%)        • Deflection rate: 0%→70%   │
│  • Compliance: GDPR, EU AI Act       • Talent: $500K/yr              • CSAT: 78%→92%             │
│  • Risks: Bias, hallucinations,      • FinOps: Cost allocation,      • ROI: 234% (payback <6mo) │
│    prompt injection (mitigated)      •   budget alerts               • 3Es: Efficiency ↓58%,     │
│  • Human-in-loop for high-stakes     • 3yr TCO: $1.59M               •   Effectiveness ↑18%,     │
│                                      • 3yr value: $5M+ (314% ROI)    •   UX ↓94% wait time       │
│                                                                                                   │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## Section-by-Section Prompts & Examples

### #1 AI Vision & Business Outcomes (Why)

**Prompts to Complete:**

1. **Vision Statement:** What is the "North Star" that explains why you're investing in AI? (1-2 sentences)
2. **Business Outcomes:** What specific, measurable outcomes do you expect? (3-5 bullet points with numbers)
3. **Competitive Advantage:** How will AI differentiate you from competitors?
4. **Transformational Opportunities:** What entirely new business models, markets, or capabilities could AI unlock?
5. **Timeline:** What's the overall roadmap horizon? (12 months, 18 months, 3 years?)

**Example Answers:**

```
VISION STATEMENT:
"Become the first AI-native healthcare platform that predicts patient needs before 
they arise, shifting from reactive treatment to proactive wellness."

BUSINESS OUTCOMES:
• Reduce patient readmission rates by 35% within 18 months
• Increase revenue per patient by $1,200/year through personalized care plans
• Expand into 5 new markets (rural areas) with AI-powered telemedicine
• Achieve 95%+ patient satisfaction (currently 82%)
• Lower operational costs by 25% through intelligent automation

COMPETITIVE ADVANTAGE:
Proprietary AI model trained on 10M+ patient records (largest dataset in our 
vertical), enabling 48-hour health risk predictions vs competitors' 7-day forecasts.

TRANSFORMATIONAL OPPORTUNITIES:
• Launch B2B2C "Wellness Coach API" for insurance partners ($10M ARR potential)
• Create AI-driven clinical trials recruitment platform (new $50M market)
• Data flywheel: More patients → better AI → better outcomes → more patients

TIMELINE: 24-month roadmap (Q1 2026 - Q4 2027)
```

**Key Questions (AI Panel Content):**

- What are your primary business objectives for AI?
- What long-term AI-driven vision sets you apart?
- How does AI create competitive advantage in your market?
- What transformational opportunities (new business models, markets) could AI unlock?

---

### #2 AI Value Proposition (What)

**Prompts to Complete:**

1. **For Customers:** How will AI improve the customer experience? What problems does it solve?
2. **For the Business:** What financial and operational value will AI create?
3. **New Products/Services:** Will AI enable entirely new offerings?
4. **Unique Differentiation:** What makes your AI solution different from competitors?
5. **Customer Problems Solved:** List specific pain points and how AI addresses them.

**Example Answers:**

```
FOR CUSTOMERS:
• Personalized product recommendations with 85% accuracy (vs 40% today)
• Instant visual search: Upload photo, find exact match in <2 seconds
• Virtual try-on with body scanning (95% fit accuracy vs 60% returns today)
• 24/7 style advisor chatbot in 12 languages
• Proactive restock alerts for favorite items (AI predicts preferences)

FOR THE BUSINESS:
• $3M annual revenue increase from AI-driven upsell/cross-sell
• $1.2M cost savings from automated customer service (70% deflection)
• Reduce product returns by 40% (AI-powered sizing recommendations)
• Enter Gen-Z market segment (new $8M TAM) with AI-first mobile app
• 2.5x conversion rate improvement from personalized landing pages

NEW PRODUCTS/SERVICES:
• "Style Studio AI" subscription tier (+$15/mo): Unlimited virtual try-ons, 
  personalized mood boards, early access to AI-curated collections
• B2B "Fashion AI API" for boutique retailers ($500/mo licensing)
• "AI Stylist Marketplace" connecting customers with human stylists for 
  high-value purchases (take 20% commission)

UNIQUE DIFFERENTIATION:
• Only fashion retailer with proprietary body-scanning AI (patented tech)
• "Ethical AI" transparency: Show why recommendations were made
• Hybrid model: AI for discovery, human stylists for final decisions

CUSTOMER PROBLEM SOLVED:
Pain: "I order 5 sizes because I don't know what fits"
Solution: AI body scan recommends exact size with 95% accuracy

Pain: "I waste hours browsing and still can't find what I want"
Solution: AI visual search finds perfect match from photo in 2 seconds
```

**Key Questions (AI Panel Content):**

- What new products or services will AI enable?
- How will AI create hyper-personalized experiences at scale?
- What unique customer problems can AI solve that competitors can't?
- How will AI differentiate you in the market?

---

### #3 Key Use Cases & Prioritisation (Why)

**Prompts to Complete:**

1. **List Top 3-5 Use Cases:** What are the highest-value AI initiatives?
2. **Prioritise by Impact:** Business value, customer benefit, competitive edge (1-5 stars)
3. **Assess Feasibility:** Technical readiness, data availability, talent (1-5 stars)
4. **Evaluate Viability:** ROI, cost, time-to-value, risk (1-5 stars)
5. **Quick Wins vs Long-Term Bets:** Which are immediate (Q1-Q2) vs future (2027+)?

**Example Answers:**

```
HIGH PRIORITY (Q1-Q2 2026):

✓ 1. Conversational AI for sales qualification (lead scoring chatbot)
     Impact: ★★★★★ (Increase qualified leads by 60%, $2M pipeline impact)
     Feasibility: ★★★★★ (Existing CRM data, off-the-shelf LLM)
     Viability: ★★★★★ (ROI in 3 months, low cost)
     → QUICK WIN: Deploy in 6 weeks

✓ 2. Predictive churn model for enterprise customers
     Impact: ★★★★★ (Prevent $5M annual churn, 35% at-risk customers)
     Feasibility: ★★★★☆ (Good data, need ML engineer hire)
     Viability: ★★★★☆ (12-month ROI, requires model maintenance)
     → STRATEGIC: Build in Q2, launch Q3

MEDIUM PRIORITY (Q3-Q4 2026):

• 3. AI-powered contract review and risk flagging
     Impact: ★★★★☆ (Save 20 hours/week for legal team)
     Feasibility: ★★★☆☆ (Complex NLP, domain-specific training)
     Viability: ★★★☆☆ (Hard to quantify ROI, but high value)

• 4. Automated competitive intelligence (web scraping + analysis)
     Impact: ★★★☆☆ (Better positioning, faster product decisions)
     Feasibility: ★★★★☆ (Existing tools available)
     Viability: ★★★★☆ (Low cost, clear time savings)

LOW PRIORITY (2027+):

• 5. Generative AI for automated blog/SEO content
• 6. AI-driven dynamic pricing optimization
• 7. Voice AI for sales call coaching

EVALUATION CRITERIA:
• Impact: Revenue growth, cost reduction, customer satisfaction, competitive edge
• Feasibility: Data availability, technical complexity, talent on hand
• Viability: Time-to-value, ROI timeline, cost to build/maintain, risk level

PRIORITISATION FRAMEWORK:
Quick Wins (High Impact + High Feasibility): #1, #4
Strategic Bets (High Impact + Medium Feasibility): #2, #3
Moonshots (High Impact + Low Feasibility): Deferred to 2027+
```

**Key Questions (AI Panel Content):**

- What are the top 3-5 business problems AI can solve?
- How do you prioritise by impact, feasibility, and time-to-value?
- Which are quick wins (deploy in <3 months) vs long-term bets?
- Common industry use cases: Predictive maintenance, fraud detection, conversational AI, 
  churn prediction, personalization, content generation, code assistance?

---

### #4 Data Strategy & Assets (How)

**Prompts to Complete:**

1. **Internal Data Sources:** What data do you already have? (tickets, logs, CRM, usage data)
2. **External Data Sources:** What third-party or open datasets will you use?
3. **Data Quality:** How clean, labeled, and usable is your data?
4. **Data Accessibility:** How will teams access data? (APIs, dashboards, self-service)
5. **Governance:** Who owns data? How is PII/sensitive data protected?
6. **AI Flywheel:** How does your product generate data that improves AI that improves product?

**Example Answers:**

```
INTERNAL DATA SOURCES:
✓ 15M user sessions (web + mobile, 3 years of analytics)
✓ 2M transactions with purchase history, cart abandonment
✓ 500K customer support tickets (chat, email, phone transcripts)
✓ Product catalog: 50K SKUs with metadata, images, specs
✓ NPS surveys: Quarterly feedback from 10K+ customers
✓ A/B test results: 200+ experiments with outcome data

EXTERNAL DATA SOURCES:
• Industry benchmarks: Forrester, Gartner reports
• Open datasets: Common Crawl for language model training
• Third-party enrichment: Clearbit for firmographic data (B2B)
• Weather data: Correlate with purchase behavior (seasonal products)
• Economic indicators: Predict demand fluctuations

DATA QUALITY & GOVERNANCE:
• Quality: 70% of support tickets have clean labels (intent, sentiment)
  → Goal: 90% by Q2 via automated tagging + human validation
• Labeling: Hired 2 data annotators, using LabelStudio for workflow
• PII scrubbing: Automated regex + NER models remove emails, SSNs, addresses
• Compliance: GDPR-compliant data retention (3-year auto-delete)
• Audits: Quarterly InfoSec review + annual SOC 2 audit

DATA ACCESSIBILITY:
• Data warehouse: BigQuery (centralized, all teams have read access)
• API: REST + GraphQL for real-time queries
• Self-service: Looker dashboards for product/marketing teams
• Notebooks: Jupyter for data science experimentation
• Data catalog: Alation documents all datasets, lineage, owners

DATA OWNERSHIP:
• Data Engineering owns infrastructure, quality, governance
• Product teams own domain-specific datasets (e.g., Support owns tickets)
• Legal/Compliance approves all external data sharing
• RBAC: Role-based access control (analysts can't see PII without audit)

AI FLYWHEEL DESIGN:
Product generates data (user behavior) 
  → AI analyzes patterns (personalization model) 
  → Improves product (better recommendations) 
  → Attracts more users 
  → More data 
  → Better AI 
  → Repeat

Example in action:
Week 1: Recommendation accuracy 40% → 10% CTR
Week 12: 500K more sessions → accuracy 65% → 18% CTR
Week 24: 2M sessions → accuracy 80% → 25% CTR
→ Virtuous cycle: More users = smarter AI = better product
```

**Key Questions (AI Panel Content):**

- What internal and external data sources are available?
- What makes data "usable" for AI? (Quality, labels, accessibility, volume)
- How will you govern data? (Privacy, compliance, ownership)
- How can you design an AI flywheel? (Product → Data → AI → Product)

---

### #5 AI Platform & Technology Stack (How)

**Prompts to Complete:**

1. **Cloud & Infrastructure:** Which cloud providers? (AWS, Azure, GCP, on-prem)
2. **AI/ML Tools:** Which LLMs, frameworks, vector databases?
3. **Build vs Buy vs Partner:** What will you build in-house vs license?
4. **AI Lifecycle:** How do you move from experiment → staging → production?
5. **Operating Model:** Centralized platform team, hub-and-spoke, or decentralized?

**Example Answers:**

```
TECH STACK DECISIONS:

CLOUD & INFRASTRUCTURE:
• Primary: Google Cloud Platform (BigQuery, Vertex AI)
• Secondary: AWS (S3 for backups, SageMaker for experiments)
• Hybrid: On-prem GPU cluster for sensitive model training (healthcare compliance)

AI/ML TOOLS:
• LLMs: OpenAI GPT-4o (primary), Anthropic Claude 3.5 (fallback for long context)
• Fine-tuning: Custom domain model on Vertex AI (medical terminology)
• Vector database: Weaviate for semantic search, RAG
• Orchestration: LangChain for prompt chaining, custom Python for complex flows
• Monitoring: Arize AI for model drift detection, Datadog for infra
• Experimentation: Weights & Biases (W&B) for experiment tracking
• Frameworks: PyTorch for custom models, scikit-learn for classical ML

BUILD vs BUY vs PARTNER:
BUILD:
  • Custom churn prediction model (competitive advantage, proprietary data)
  • Domain-specific chatbot orchestration (unique workflows)
  • Data pipeline (dbt, Airflow for ETL)

BUY:
  • OpenAI API (LLM inference, too expensive to train from scratch)
  • Weaviate (vector DB, faster than building)
  • Arize AI (monitoring, proven tooling)

PARTNER:
  • Google Cloud (managed Vertex AI, reduce ops overhead)
  • Snowflake for data warehousing (already integrated)
  • External consultancy for EU AI Act compliance (12-week engagement)

AI LIFECYCLE:

EXPERIMENT → STAGING → PRODUCTION:

1. EXPERIMENT (Data Science Team):
   • Environment: Jupyter notebooks, local GPU workstation
   • Tools: W&B for tracking, PyTorch for prototyping
   • Duration: 2-4 weeks per experiment
   • Output: Model with >80% accuracy on test set

2. STAGING (ML Engineering Team):
   • Environment: GCP Vertex AI staging project
   • Tools: Dockerized model, A/B testing framework
   • Testing: Shadow mode (run alongside production, compare results)
   • Duration: 2 weeks
   • Gate: Product + Engineering sign-off

3. PRODUCTION (MLOps Team):
   • Environment: GCP Vertex AI production project, auto-scaled
   • Deployment: Blue-green deployment, gradual rollout (10%→50%→100%)
   • Monitoring: Real-time dashboards (latency, accuracy, drift)
   • Rollback: Feature flags allow instant revert if accuracy drops >5%
   • Duration: 1 week rollout

OPERATING MODEL:

Centralized AI Platform Team (5 people):
  • 2 ML Platform Engineers (build infra, tools, pipelines)
  • 1 MLOps Engineer (deployment, monitoring, SRE)
  • 1 Data Engineer (data quality, feature store)
  • 1 AI Product Manager (roadmap, prioritization)

Hub-and-Spoke Model:
  • HUB: Platform team provides reusable infra (feature store, model registry, 
    deployment pipelines, monitoring dashboards)
  • SPOKES: Product teams own domain-specific use cases (Sales AI, Support AI, 
    Marketing AI) and build models using platform tools
  • Governance: Centralized AI Steering Committee approves all production deployments

Decentralized Experimentation:
  • Any PM/engineer can run experiments in sandbox environment
  • Monthly "AI Demo Day" to share learnings
  • Top 3 experiments get platform team support to productionize

DEPLOYMENT STRATEGY:
• Phased rollout: 10% of users for 1 week → monitor metrics → 50% for 1 week → 100%
• Canary deployments: New model runs alongside old, compare performance
• A/B testing: Control (no AI) vs Treatment (AI) for 2 weeks before full launch
• Automated rollback: If error rate >1% or latency >500ms, auto-revert
```

**Key Questions (AI Panel Content):**

- Which tech stack will you use? (Cloud, hardware, vendors, frameworks)
- Build vs Buy vs Partner decisions?
- How will you manage the AI lifecycle from experiment to production?
- What operating model? (Centralized platform, hub-and-spoke, decentralized)

---

### #6 People, Skills & Culture (How)

**Prompts to Complete:**

1. **Current Talent:** Who do you have today? (data scientists, ML engineers, AI PMs)
2. **Hiring Roadmap:** Who will you hire in the next 12 months?
3. **Skills Development:** How will you upskill existing teams?
4. **Culture Shifts:** How will you shift from "AI is scary" to "AI augments us"?
5. **Change Management:** How will you address employee concerns? (job displacement, transparency)

**Example Answers:**

```
CURRENT STATE (Talent Inventory):

DATA & AI TEAM:
• 0 ML engineers (hiring 3 in Q1)
• 1 data scientist (generalist, part-time on AI projects)
• 0 AI product managers (promoting 1 internal PM in Q2)
• 2 data engineers (pipeline, ETL, data quality)
• 0 MLOps engineers (hiring 1 in Q2)
• 0 AI ethicist (consultant engagement for 6 months)

OTHER TEAMS:
• 8 product engineers (2 have ML experience, upskilling others)
• 3 product managers (AI fluency training planned)
• 50 customer support agents (will become "AI trainers" for chatbot)
• 1 CTO (AI sponsor, technical oversight)

HIRING ROADMAP (12 months):

Q1 2026:
• 2 Senior ML Engineers ($180K-$220K each)
• 1 Junior ML Engineer ($120K)
• 1 AI Product Manager ($160K)

Q2 2026:
• 1 MLOps Engineer ($150K)
• 1 Conversational AI Designer ($130K)

Q3 2026:
• 1 AI Strategist / Head of AI ($200K+)
• 2 Data Annotators (contract, $40/hr)

Q4 2026:
• 1 AI Ethicist (part-time consultant → full-time hire, $140K)

TOTAL YEAR 1 HIRING COST: ~$1.2M (salaries + benefits + recruiting)

SKILLS DEVELOPMENT (Upskilling):

ALL EMPLOYEES:
• "AI Fluency Fundamentals" workshop (2-day, mandatory for all PMs, engineers)
  Topics: LLMs, prompting, use cases, ethics, limitations
• Monthly AI Town Halls: CTO shares progress, demos, Q&A
• Access to Coursera/Udemy AI courses (company-paid)

PRODUCT MANAGERS:
• "AI Product Management" certification (Reforge, 6-week program)
• Hands-on: Build a chatbot prototype using no-code tools (Voiceflow)

ENGINEERS:
• "Practical Machine Learning" bootcamp (fast.ai, 10-week course)
• Pair programming with ML engineers on real projects
• Hack days: Monthly 2-day AI experiments (winner gets $5K bonus)

CUSTOMER SUPPORT AGENTS:
• New role created: "AI Trainer" (10% of agents, +$10K/yr salary bump)
  Responsibilities: Label chatbot training data, review AI responses, 
                   escalate edge cases, provide feedback to ML team
• Career path: Agent → AI Trainer → CX Specialist → CX Manager

LEADERSHIP:
• Executive GenAI workshop (Harvard Business School, 3-day program)
• Site visits to AI-first companies (OpenAI, Anthropic, Scale AI)

CULTURE SHIFTS:

FROM "AI will replace us" → TO "AI augments us"

TACTICS:
1. Transparency:
   • Weekly "AI in Plain English" email from CTO (no jargon)
   • Slack #ai-updates channel with real-time progress
   • Open roadmap: Everyone can see what's being built and why

2. Inclusive Design:
   • Support agents co-design chatbot personality, tone, escalation rules
   • "AI Champions" program: 1 volunteer per team embeds with ML team
   • Monthly demo days: ML team shows work-in-progress, gets feedback

3. Celebrate Wins:
   • "AI Impact Award" ($1K bonus) for best AI-driven improvement each quarter
   • Case studies: "How Sarah (support agent) saved 10 hrs/week with AI"
   • All-hands: Share customer testimonials about AI features

4. Address Fears:
   • 1:1s with all support agents: "Your job is safe, we're adding AI to help you 
     handle tier-1 so you can focus on complex, high-value interactions"
   • No-layoff pledge for 18 months while AI is being implemented
   • Reskilling budget: $5K/employee for courses, certifications

5. Incentives Aligned:
   • Performance reviews include "AI collaboration" metric (did you help train AI?)
   • Career paths updated: IC → AI Specialist track (not just manager track)
   • Bonuses tied to AI success metrics (if chatbot hits 70% deflection, everyone 
     gets 5% bonus)

CHANGE MANAGEMENT (Addressing Employee Concerns):

CONCERN #1: "Will AI take my job?"
RESPONSE:
  • No layoffs for 18 months (written policy)
  • AI handles tier-1 (FAQs, routing), humans handle tier-2/3 (complex, emotional)
  • New roles created: AI Trainer, CX Specialist, Escalation Expert
  • Career path: We're investing in YOU to become AI-savvy, not replacing you

CONCERN #2: "I don't understand AI, I'll fall behind"
RESPONSE:
  • Mandatory AI fluency training (paid work time, not after-hours)
  • Buddy system: Pair non-technical staff with ML engineers
  • "Ask Me Anything" sessions with data scientists (no stupid questions)
  • Learning stipend: $2K/year for courses, conferences, books

CONCERN #3: "AI will make mistakes and I'll get blamed"
RESPONSE:
  • Human-in-loop for high-stakes decisions (refunds >$500, account deletions)
  • AI confidence scores visible to agents (if <80%, escalate to human)
  • Blameless postmortems: If AI fails, we fix the system, not punish the person
  • Agents have override button (can always choose human response over AI)

PILOT TEAM APPROACH:
• Start with 5 "AI Champion" support agents (volunteers)
• They test chatbot, provide feedback, become internal advocates
• After 3 months, expand to 20 agents, then full team
• Champions get first access to new AI tools, input on roadmap

METRICS TO TRACK:
• Employee AI fluency score: Quarterly quiz (target: 80% pass rate)
• AI tool adoption: % of employees using AI features weekly (target: 60%)
• Employee NPS on AI tools (target: 8+/10)
• Retention rate of "AI-adjacent" roles (target: >90%)
```

**Key Questions (AI Panel Content):**

- What AI talent do you need? (Data scientists, ML engineers, AI strategists)
- How will you build an AI-ready culture?
- What's your AI fluency strategy for non-technical staff?
- How will you address change management and employee concerns about job displacement?

---

### #7 Governance & Responsible AI (What)

**Prompts to Complete:**

1. **Accountability:** Who is responsible for AI decisions? (steering committee, ethics officer)
2. **Responsible AI Framework:** How will you ensure fairness, transparency, privacy, safety?
3. **Risk Mitigation:** What are the top AI risks and how will you mitigate them?
4. **Compliance:** Which regulations apply? (GDPR, EU AI Act, industry standards)
5. **Human-in-Loop:** When do humans override AI decisions?

**Example Answers:**

```
ACCOUNTABILITY STRUCTURE:

AI STEERING COMMITTEE (Executive Level):
• Meets: Monthly
• Members: CEO, CTO, CFO, Head of Product, Head of Legal, Head of Customer Success
• Responsibilities:
  - Approve all high-risk AI use cases (customer-facing, financial impact >$500K)
  - Review quarterly AI ethics audits
  - Set AI budget and strategic priorities
  - Escalation point for AI incidents

AI ETHICS OFFICER:
• Role: Head of Product (interim), hiring dedicated AI Ethicist in Q2
• Responsibilities:
  - Design Responsible AI framework
  - Quarterly bias audits (gender, race, language, geography)
  - Review all customer-facing AI before production launch
  - Incident response lead for AI failures (hallucinations, bias, safety)

DATA PRIVACY LEAD:
• Role: Legal Counsel + VP of Security
• Responsibilities:
  - GDPR/CCPA compliance for all AI data usage
  - PII scrubbing and anonymization pipelines
  - Data retention and deletion policies
  - Customer data portability and "right to explanation" requests

MODEL OWNERS (Domain Teams):
• Each AI use case has a Product Manager owner who is accountable for:
  - Model performance (accuracy, latency, uptime SLAs)
  - Fairness metrics (bias monitoring)
  - Customer impact (NPS, support tickets related to AI)
  - Financial ROI

RESPONSIBLE AI FRAMEWORK (6 Pillars):

1. FAIRNESS:
   • Bias audits quarterly (test model on demographic slices: gender, age, language)
   • Fairness metrics: Equal opportunity, demographic parity
   • Mitigation: Re-weight training data, adversarial debiasing
   • Example: Chatbot tested for equal response quality across 10 languages

2. TRANSPARENCY:
   • "Why this answer?" feature in chatbot (show sources, confidence score)
   • Model cards published for all production models (architecture, training data, 
     limitations, intended use)
   • Customer-facing AI disclaimer: "This response is AI-generated, reviewed by humans"

3. PRIVACY:
   • PII scrubbing: Automated removal of emails, SSNs, addresses from training data
   • On-device inference: Sensitive data (health, financial) processed locally, not 
     sent to cloud
   • Data minimization: Collect only what's needed, delete after 3 years (GDPR)
   • Encryption: All AI training data encrypted at rest and in transit

4. SAFETY:
   • Human-in-loop for high-stakes decisions:
     - Billing disputes >$500 require human approval
     - Account deletions require human confirmation
     - Medical/legal advice: AI refuses to answer, routes to human expert
   • Guardrails: Input validation (block prompt injection), output filtering (no 
     harmful content)
   • Fallback: If AI confidence <80%, escalate to human

5. ACCOUNTABILITY:
   • Audit logs: Every AI decision logged with model version, input, output, timestamp
   • Version control: All prompts, model weights versioned (Git, MLflow)
   • Incident response: 24-hour SLA for critical AI failures, root cause analysis within 
     72 hours
   • Customer recourse: "Report AI error" button in chatbot → human reviews within 4 hours

6. RELIABILITY:
   • Uptime SLA: 99.9% for customer-facing AI
   • Monitoring: Real-time dashboards for accuracy, latency, error rate
   • Automated rollback: If error rate >1%, auto-revert to previous model version
   • Redundancy: Fallback to rule-based system if LLM API is down

RISKS & MITIGATION:

⚠ RISK #1: Bias (AI gives worse responses to non-English speakers)
MITIGATION:
  • Quarterly bias audits across 10 languages
  • Balanced training data (equal samples per language)
  • Fairness metrics in production dashboards
  • Escalation: If bias detected, pause rollout, retrain model

⚠ RISK #2: Hallucinations (AI makes up facts, wrong answers)
MITIGATION:
  • Confidence scores: Show "80% confident" to users, escalate if <70%
  • Source attribution: AI cites knowledge base article, not free-form generation
  • Human validation: 10% of AI responses randomly reviewed by agents
  • Fallback: If no confident answer, AI says "I don't know, let me connect you to a human"

⚠ RISK #3: Prompt Injection (malicious users manipulate AI)
MITIGATION:
  • Input validation: Block common injection patterns ("Ignore previous instructions")
  • Rate limiting: Max 20 requests/minute per user
  • Monitoring: Flag unusual input patterns (e.g., 10x longer than average prompt)
  • Sandboxing: AI cannot access internal systems, only predefined knowledge base

⚠ RISK #4: Data Leakage (AI reveals customer PII)
MITIGATION:
  • PII scrubbing: Automated removal of sensitive data before training
  • Encrypted storage: All training data encrypted (AES-256)
  • Access control: RBAC (only ML engineers can access raw data, not PII)
  • Audits: Annual penetration testing, SOC 2 compliance

⚠ RISK #5: Model Drift (AI accuracy degrades over time)
MITIGATION:
  • Real-time monitoring: Arize AI tracks accuracy, precision, recall daily
  • Retraining schedule: Quarterly model retraining with latest data
  • A/B testing: Always compare new model vs current before full rollout
  • Alerts: If accuracy drops >5%, auto-notify ML team, consider rollback

COMPLIANCE:

GDPR (General Data Protection Regulation):
• Right to explanation: Customers can request "Why did AI make this decision?"
  → Model cards + audit logs provide this
• Data portability: Customers can export all their data, including AI interactions
• Right to deletion: Customers can request data deletion → automated within 30 days
• Data minimization: Only collect data necessary for AI use case, delete after 3 years

EU AI ACT (High-Risk AI Classification):
• Our chatbot is "high-risk" (customer-facing, impacts customer service quality)
• Requirements:
  - Risk management system: Document all risks, mitigations (done in this section)
  - Data governance: Quality, bias audits (quarterly audits planned)
  - Transparency: Customers must know they're interacting with AI (disclaimer added)
  - Human oversight: Human-in-loop for high-stakes decisions (implemented)
  - Accuracy: Robust model validation, monitoring (95%+ accuracy SLA)
  - Cybersecurity: Encryption, access control (SOC 2 compliant)

SOC 2 (Security, Availability, Confidentiality):
• Annual SOC 2 Type II audit (covers AI systems)
• Controls: Audit logs, encryption, access control, incident response
• AI-specific: Model versioning, data lineage, bias monitoring

INDUSTRY STANDARDS:
• ISO 42001 (AI Management System): Roadmap to achieve certification by Q4 2026
• NIST AI Risk Management Framework: Adopted as internal standard

HUMAN-IN-LOOP RULES:

ALWAYS REQUIRE HUMAN APPROVAL:
1. Financial transactions >$500 (refunds, credits, discounts)
2. Account deletions or suspensions
3. Medical/legal advice (AI refuses, routes to human expert)
4. Escalations marked "urgent" or "angry" by sentiment analysis
5. Any decision with AI confidence <70%

HUMAN REVIEW (ASYNC):
• 10% random sample of AI responses reviewed weekly by support agents
• All customer-reported AI errors reviewed within 4 hours
• Monthly "edge case review" session: ML team + support agents discuss weird cases

ESCALATION PATH:
• Customer can always click "Talk to a human" button (< 30 sec wait time)
• Agents can override AI suggestions 100% of the time (no questions asked)
• Weekly agent feedback session: "What did AI get wrong this week?"

TRANSPARENCY TO CUSTOMERS:
• Chatbot starts every conversation: "Hi! I'm an AI assistant. I can help with most 
  questions, but I'll connect you to a human if needed."
• AI confidence shown: "I'm 85% confident this answer is correct. Want me to double-check 
  with a human?"
• Feedback loop: "Was this answer helpful? [Yes] [No] [Report error]"
```

**Key Questions (AI Panel Content):**

- Who is accountable for AI decisions in your organization?
- What is your Responsible AI framework? (Fairness, transparency, privacy, safety)
- What are the top AI risks and mitigation strategies? (Bias, hallucinations, prompt injection)
- Which regulations apply? (GDPR, EU AI Act, industry standards)
- When do humans override AI? (High-stakes decisions, low confidence, customer request)

---

### #8 Cost Structure & Financial Management (What)

**Prompts to Complete:**

1. **Cost Drivers:** What are the main cost components? (LLM API, compute, storage, talent)
2. **Zig-Zag Pattern:** Where will costs spike (launch) and plateau (optimization)?
3. **Compute Optimization:** How will you reduce AI costs over time?
4. **FinOps for AI:** How will you track, allocate, and optimize AI spending?
5. **Total Cost of Ownership (TCO):** What's the 3-year TCO including maintenance?

**Example Answers:**

```
COST DRIVERS (Breakdown):

YEAR 1 COSTS (SETUP + ONGOING):

1. LLM API CALLS (70% of ongoing costs):
   • OpenAI GPT-4o: $0.03/1K tokens (input) + $0.06/1K tokens (output)
   • Estimated usage: 10M tokens/month (chatbot, 5K conversations/day)
   • Monthly cost: $0.03 × 5M + $0.06 × 5M = $150 + $300 = $450
   • Annual: $450 × 12 = $5,400
   • Spikes: Launch month 3x (testing, high traffic) = $1,350
   → TOTAL YEAR 1: $6,750

2. COMPUTE (TRAINING, INFERENCE) (20% of ongoing costs):
   • Training: AWS p3.8xlarge (4 GPUs) for custom model fine-tuning
     - $12.24/hour × 100 hours/quarter = $1,224/quarter = $4,896/year
   • Inference: AWS ECS Fargate (CPU-only, auto-scaled)
     - $0.04/vCPU-hour × 2 vCPU × 730 hrs/mo = $58/mo = $696/year
   → TOTAL YEAR 1: $5,592

3. STORAGE (VECTORS, LOGS, TRAINING DATA) (5% of ongoing costs):
   • Vector database (Pinecone): $0.096/GB/month × 50 GB = $4.80/mo = $57.60/year
   • S3 storage: $0.023/GB/month × 500 GB (logs, models) = $11.50/mo = $138/year
   • Training data (Snowflake): $2/TB/month × 1 TB = $2,000/year
   → TOTAL YEAR 1: $2,196

4. TALENT (SALARIES + BENEFITS) (Largest cost):
   • 2 ML Engineers: $180K + $220K = $400K
   • 1 Junior ML Engineer: $120K
   • 1 AI Product Manager: $160K
   • 1 MLOps Engineer (joins Q2): $150K × 0.75 = $112.5K
   → TOTAL YEAR 1: $792.5K

5. TOOLING & LICENSES (5% of ongoing costs):
   • Arize AI (monitoring): $500/mo = $6K/year
   • Weights & Biases (experiment tracking): $200/mo = $2.4K/year
   • Snowflake (data warehouse): Included in storage above
   • GitHub Copilot for engineers: $19/user/mo × 8 = $152/mo = $1,824/year
   → TOTAL YEAR 1: $10,224

6. ONE-TIME SETUP COSTS:
   • Infrastructure setup (AWS, Pinecone, Snowflake configs): $5K (contractor)
   • Model fine-tuning (initial training): $10K (GPU compute)
   • Data annotation (labeling 50K support tickets): $15K (contractors)
   • AI fluency training (workshops, courses): $20K
   → TOTAL ONE-TIME: $50K

TOTAL YEAR 1 COSTS:
• Setup: $50K
• Ongoing: $14.5K/month × 12 = $174K (LLM, compute, storage, tooling)
• Talent: $792.5K
→ GRAND TOTAL YEAR 1: $1,016,500 (~$1.02M)

ZIG-ZAG COST PATTERN:

AI costs don't follow traditional linear IT spending. They spike and drop unpredictably.

MONTH 1-3 (LAUNCH SPIKE):
• Costs: 3x normal (experimentation, testing, high traffic during beta)
• LLM API: $1,350/month (vs $450 normal)
• Compute: 5x training runs (finding optimal model)
• Reason: Lots of trial-and-error, A/B tests, retraining

MONTH 4-6 (PLATEAU):
• Costs: 1.5x normal (still optimizing)
• LLM API: $675/month
• Reason: Reduced testing, but still iterating on prompts

MONTH 7-12 (OPTIMIZATION):
• Costs: 0.7x normal (after optimizations kick in)
• LLM API: $315/month (30% reduction via caching, smaller models)
• Reason: Implemented cost-saving measures (see below)

YEAR 2 (EFFICIENCY):
• Costs: 0.5x Year 1 ongoing (50% reduction)
• LLM API: $225/month (switched to cheaper models for 60% of requests)
• Reason: Mature system, optimized prompts, better caching

COMPUTE OPTIMIZATION STRATEGIES:

1. CACHING:
   • Cache common questions: "What's your return policy?" asked 500x/day
   • Store AI response for 24 hours → 99.8% cache hit rate
   • Cost savings: 40% reduction in LLM API calls
   • Implementation: Redis cache layer before LLM

2. MODEL DISTILLATION:
   • Train smaller model (GPT-3.5-turbo) on GPT-4o outputs for simple tasks
   • Use GPT-4o only for complex questions (20% of traffic)
   • Cost savings: 60% reduction (GPT-3.5 is 10x cheaper than GPT-4o)
   • Implementation: Classifier routes simple→small model, complex→large model

3. BATCH INFERENCE:
   • Run non-urgent tasks (weekly reports, analytics) during off-peak hours (2-6am)
   • Negotiate with AWS for spot instances (70% discount)
   • Cost savings: 30% reduction on compute costs
   • Implementation: Airflow schedules batch jobs at night

4. RIGHT-SIZE COMPUTE:
   • Training: Use GPUs (p3.8xlarge) only during training
   • Inference: Use CPUs (Fargate) for serving (10x cheaper than GPU for inference)
   • Cost savings: 80% reduction on inference costs
   • Implementation: Separate training and serving infrastructure

5. PROMPT OPTIMIZATION:
   • Shorten prompts: 500 tokens → 200 tokens (reduce input costs)
   • Use few-shot examples only when needed (not every request)
   • Cost savings: 40% reduction on input token costs
   • Implementation: A/B test prompt lengths, keep shortest that maintains accuracy

6. OPEN-SOURCE ALTERNATIVES:
   • Experiment with Llama 3 (free, self-hosted) for non-customer-facing use cases
   • Cost savings: $0 vs $450/month for internal tools
   • Tradeoff: Higher setup cost, need to manage infrastructure

FINOPS FOR AI (Financial Operations):

1. COST ALLOCATION BY USE CASE:
   • Tag every LLM API call with use case ID (chatbot, sentiment analysis, etc.)
   • Monthly report: "Chatbot cost $3K, Sentiment cost $500, etc."
   • Accountability: Product teams "own" their AI budgets

2. BUDGET ALERTS:
   • Set monthly budget: $500/month per use case
   • Alert at 80% ($400 spent) → email to PM + ML engineer
   • Hard stop at 120% ($600) → auto-pause API calls, requires CTO approval to resume
   • Tool: AWS Cost Anomaly Detection

3. MONTHLY COST REVIEW:
   • Product + Finance + ML team meet 1st Monday of month
   • Review: What spiked? Why? ROI per use case?
   • Action: Kill low-ROI use cases, double down on high-ROI

4. ROI TRACKING PER INITIATIVE:
   • Chatbot: Cost $5K/mo, saves $20K/mo in agent time → 4x ROI
   • Sentiment analysis: Cost $500/mo, prevents $10K churn/mo → 20x ROI
   • Churn prediction: Cost $2K/mo, saves $50K churn/mo → 25x ROI
   → Kill initiatives with <2x ROI

5. COST OPTIMIZATION GOALS:
   • Q1: Reduce LLM API costs by 20% (caching)
   • Q2: Reduce compute costs by 30% (right-size, batch inference)
   • Q3: Reduce overall AI costs by 40% (model distillation)
   • Q4: Maintain costs flat despite 2x traffic growth (efficiency gains)

TOTAL COST OF OWNERSHIP (TCO) - 3 YEARS:

YEAR 1: $1,016,500
• Setup: $50K
• Ongoing: $174K (LLM, compute, storage, tooling)
• Talent: $792.5K

YEAR 2: $580,000 (43% reduction due to optimizations)
• Ongoing: $80K (50% reduction via caching, distillation, batch inference)
• Talent: $500K (less hiring, more efficient team)

YEAR 3: $450,000 (mature, optimized system)
• Ongoing: $70K (continued efficiency gains)
• Talent: $380K (smaller team, more automation)

3-YEAR TCO: $2,046,500 (~$2.05M)

VALUE CREATED (3 YEARS):
• Cost savings: $800K/year × 3 = $2.4M (reduced support headcount)
• New revenue: $2M/year × 3 = $6M (upsell insights, SMB segment)
• TOTAL VALUE: $8.4M

3-YEAR ROI: ($8.4M - $2.05M) / $2.05M = 310% ROI
→ For every $1 invested, we generate $4.10 in value over 3 years
```

**Key Questions (AI Panel Content):**

- What are the main cost drivers? (Compute, storage, talent, licensing, API calls)
- How will you optimize compute costs? (Caching, batching, right-sizing, model distillation)
- What is your FinOps strategy for AI? (Budget alerts, cost allocation, ROI tracking)
- What's the total cost of ownership (TCO) over 3 years, including maintenance?

---

### #9 Success Metrics & ROI (What)

**Prompts to Complete:**

1. **Business KPIs:** What key metrics will AI improve? (Revenue, cost, satisfaction, efficiency)
2. **Financial ROI:** What's the payback period, ROI percentage, net gain?
3. **Non-Financial Metrics:** How will you measure employee satisfaction, brand perception, innovation?
4. **3Es Framework:** How will AI improve Efficiency, Effectiveness, User Experience?
5. **Post-Deployment Tracking:** How will you monitor success after launch?

**Example Answers:**

```
BUSINESS KPIs (Primary Metrics):

CUSTOMER SATISFACTION:
• CSAT (Customer Satisfaction Score): 78% → 92% (target +18%)
  - Measure: Post-interaction survey "How satisfied were you?" (1-5 scale)
  - Current: 78% give 4-5 stars
  - Target: 92% give 4-5 stars within 12 months
  - AI impact: Faster responses, more accurate answers, 24/7 availability

• NPS (Net Promoter Score): 45 → 65 (target +20 points)
  - Measure: "How likely are you to recommend us?" (0-10 scale)
  - Current: 45 (industry average: 40)
  - Target: 65 (top quartile: 60+)
  - AI impact: Proactive support, personalized recommendations

OPERATIONAL EFFICIENCY:
• Support cost per ticket: $12 → $5 (target -58%)
  - Measure: Total support costs / # of tickets resolved
  - Current: $12 (includes agent salaries, tools, overhead)
  - Target: $5 (70% deflection to AI, agents handle complex only)
  - AI impact: AI chatbot handles 70% of tier-1 tickets at $2/ticket vs humans $12/ticket

• Ticket deflection rate: 0% → 70% (target: 7 out of 10 tickets resolved by AI)
  - Measure: # AI-resolved tickets / total tickets
  - Current: 0% (no AI chatbot yet)
  - Target: 70% within 6 months
  - AI impact: Chatbot handles FAQs, billing, password resets, routing

• Time to resolution: 4 hours → 15 minutes (target -94%)
  - Measure: Time from ticket creation to resolution
  - Current: 4 hours (agents handle sequentially, wait times)
  - Target: 15 minutes (AI instant response for 70% of tickets)
  - AI impact: No wait times, instant answers 24/7

SCALABILITY:
• Support team capacity: 10,000 tickets/month → 30,000 tickets/month (3x)
  - Measure: # of tickets handled without adding headcount
  - Current: 10K tickets/month with 12 agents
  - Target: 30K tickets/month with same 12 agents (+ AI)
  - AI impact: AI handles 20K tickets, agents handle 10K complex tickets

REVENUE IMPACT:
• Upsell revenue from AI insights: $0 → $2M/year
  - Measure: Revenue attributed to AI-detected upsell opportunities
  - Current: $0 (no AI-driven upsell)
  - Target: $2M/year (AI detects upgrade opportunities in support conversations)
  - Example: AI notices customer asking about feature only in Pro plan → suggests upgrade
  
• New market segment (SMB): $0 → $5M ARR
  - Measure: Annual recurring revenue from SMB customers (previously couldn't serve)
  - Current: $0 (SMB needs self-service support, we can't afford human agents)
  - Target: $5M ARR from 1,000 SMB customers at $5K/yr
  - AI impact: AI chatbot enables self-service support at scale, no human agents needed

FINANCIAL ROI (12-MONTH PAYBACK):

INVESTMENT (YEAR 1):
• Setup costs: $50K (infrastructure, training, annotation)
• Ongoing costs: $174K (LLM API, compute, storage, tooling)
• Talent: $792.5K (ML engineers, AI PM, MLOps)
→ TOTAL INVESTMENT: $1,016,500

RETURNS (YEAR 1):
• Cost savings: $800K
  - Reduce support headcount: 12 → 8 agents (-4 agents × $60K = $240K)
  - Tool consolidation: Replace 3 legacy tools with AI ($50K/year savings)
  - Reduce escalations to engineering: -50% (-$100K in eng time)
  - Overtime reduction: AI handles after-hours, no premium pay ($50K savings)
  - Real estate: Smaller support team, downsize office ($60K savings)
  - Training costs: AI onboards new agents faster ($30K savings)
  - Total: $800K/year
  
• New revenue: $2M
  - AI-detected upsell opportunities: $1.5M (500 upgrades × $3K)
  - SMB market entry: $500K in Year 1 (ramp to $5M by Year 3)
  - Reduced churn: AI flags at-risk customers → $200K churn prevented
  - Total: $2M/year

TOTAL VALUE CREATED (YEAR 1): $2.8M
NET GAIN: $2.8M - $1.02M = $1.78M
ROI: ($1.78M / $1.02M) × 100% = 175% ROI
PAYBACK PERIOD: $1.02M / ($2.8M / 12 months) = 4.4 months

→ For every $1 invested in AI, we generate $2.75 in value within 12 months
→ We break even in 4.4 months, then profit for the remaining 7.6 months

NON-FINANCIAL METRICS:

EMPLOYEE SATISFACTION:
• AI tool NPS (internal): Target 8+/10
  - Measure: Quarterly survey to support agents "How helpful is the AI chatbot?"
  - Target: 8+ (employees love it)
  - Why it matters: If agents hate AI, they won't use it or train it well

• Employee retention (AI-adjacent roles): Target >90%
  - Measure: % of ML engineers, data scientists who stay >12 months
  - Target: >90% retention (AI talent is hard to hire, expensive to replace)
  - Why it matters: High turnover = lost knowledge, project delays

• Time saved per agent: Target 10 hours/week
  - Measure: Survey "How many hours/week does AI save you?"
  - Target: 10 hours/week (agents can focus on complex, rewarding work)
  - Why it matters: Job satisfaction, productivity

BRAND PERCEPTION:
• "AI-first CX" positioning awareness: Target 40% of target market
  - Measure: Brand survey "Which companies are leaders in AI customer experience?"
  - Target: 40% of respondents mention us (up from 5% today)
  - Why it matters: Differentiation, competitive moat, premium pricing

• PR mentions: Target 20 articles/year
  - Measure: # of articles/podcasts/videos mentioning our AI capabilities
  - Target: 20 per year (TechCrunch, VentureBeat, industry podcasts)
  - Why it matters: Thought leadership, recruitment, investor confidence

INNOVATION VELOCITY:
• AI experiments shipped per quarter: Target 3
  - Measure: # of new AI features/use cases launched in production
  - Target: 3 per quarter (1 major, 2 minor)
  - Why it matters: Speed of innovation, competitive advantage

• Time from idea to production: Target <8 weeks
  - Measure: Days from "let's try this AI use case" to "it's live for customers"
  - Target: <8 weeks (2 weeks experiment, 2 weeks staging, 4 weeks rollout)
  - Why it matters: Fast iteration, first-mover advantage

3Es FRAMEWORK (Efficiency, Effectiveness, User Experience):

1. EFFICIENCY (Do more with less):
   • Cost per ticket: ↓58% ($12 → $5)
   • Agent productivity: ↑200% (handle 3x tickets with same team)
   • Time to resolution: ↓94% (4 hours → 15 minutes)
   → AI automates repetitive tasks, agents focus on high-value work

2. EFFECTIVENESS (Better outcomes):
   • First-contact resolution: ↑40% (60% → 84%)
   • Answer accuracy: ↑15% (78% → 90%+)
   • Customer retention: ↑8% (AI flags churn risks early)
   → AI makes better decisions, catches issues humans miss

3. USER EXPERIENCE (Delightful interactions):
   • Wait time: ↓94% (4 hours → 15 minutes)
   • CSAT: ↑18% (78% → 92%)
   • 24/7 availability: 0% → 100% (AI never sleeps)
   • Multilingual support: 1 language → 10 languages (instant translation)
   → AI creates faster, more consistent, more personalized experiences

POST-DEPLOYMENT TRACKING:

DASHBOARDS (REAL-TIME):
• Looker dashboard (updated hourly):
  - Ticket deflection rate (target: 70%)
  - AI accuracy (target: 90%+)
  - Customer satisfaction (target: 92%)
  - Cost per ticket (target: $5)
  - Time to resolution (target: 15 min)

WEEKLY REVIEWS:
• ML team + Product + Support leads
  - Review: What spiked? Any AI failures? Customer feedback?
  - Action: Retrain model, update prompts, escalate bugs

MONTHLY BUSINESS REVIEWS:
• Exec team + Finance
  - Review: ROI per use case, cost trends, roadmap progress
  - Action: Kill low-ROI initiatives, increase budget for high-ROI

QUARTERLY MODEL AUDITS:
• Bias audits (fairness across demographics)
• Accuracy regression tests (is model getting worse over time?)
• Cost audits (are we over-spending?)
• Security audits (any vulnerabilities?)

ANNUAL STRATEGIC REVIEW:
• Board presentation
  - 3-year ROI trajectory (are we on track for 310% ROI?)
  - Competitive landscape (did competitors catch up?)
  - Roadmap for Year 2 (what's next?)

JUSTIFICATION STATEMENT (FOR INVESTORS/BOARD):

"For every $1 invested in AI, we generate $2.75 in value within 12 months, with:
 • 58% cost efficiency improvement (cost per ticket $12 → $5)
 • 18% customer satisfaction improvement (CSAT 78% → 92%)
 • 94% reduction in wait times (4 hours → 15 minutes)
 • $2M in new revenue from AI-driven upsell insights
 • Payback period of 4.4 months, 175% ROI in Year 1, 310% ROI over 3 years.

AI is not a cost center — it's a revenue and efficiency multiplier that enables us to 
scale 3x without adding headcount, enter new markets (SMB), and differentiate on 
'AI-first customer experience' positioning."
```

**Key Questions (AI Panel Content):**

- What KPIs are linked to business outcomes? (Revenue, cost, satisfaction, retention)
- What's the financial vs non-financial ROI?
- How will you track value post-deployment? (Dashboards, reviews, audits)
- How do you measure the 3Es: Efficiency, Effectiveness, User Experience?

---

## Alternative View: Lindenberg 4-Category Lens

Some teams prefer a different grouping. Here's how the 9 boxes map to 4 categories:

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                     AI READINESS CANVAS (4-Category View)                     │
│                                Lindenberg Model                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  CATEGORY 1: STRATEGY READINESS                                              │
│  ───────────────────────────                                                 │
│  • Strategic Orientation (maps to #1 Vision + #3 Use Cases)                  │
│  • Business Value and AI (maps to #2 Value Proposition)                      │
│  • Business/AI Goals and Evaluation (maps to #9 Success Metrics & ROI)       │
│                                                                               │
│  Key questions:                                                               │
│  - Do we have a clear AI vision tied to business strategy?                   │
│  - Have we prioritized use cases by impact/feasibility/viability?            │
│  - Are success metrics defined and measurable?                               │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  CATEGORY 2: LEGAL READINESS                                                 │
│  ───────────────────────                                                     │
│  • Compliance (maps to #7 Governance & Responsible AI)                       │
│  • Internal Data Policy (maps to #4 Data Strategy, governance section)       │
│                                                                               │
│  Key questions:                                                               │
│  - Are we compliant with GDPR, EU AI Act, industry regulations?              │
│  - Do we have data governance policies (PII, retention, access control)?     │
│  - Is there a Responsible AI framework (fairness, transparency, safety)?     │
│  - Who is accountable for AI ethics and compliance?                          │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  CATEGORY 3: BUSINESS READINESS                                              │
│  ───────────────────────────                                                 │
│  • AI Competencies (maps to #6 People, Skills & Culture)                     │
│  • Processes & Use Cases (maps to #3 Key Use Cases)                          │
│  • Business Culture and AI (maps to #6 Culture section)                      │
│                                                                               │
│  Key questions:                                                               │
│  - Do we have the right talent (ML engineers, data scientists, AI PMs)?      │
│  - Is our culture AI-ready? (Mindset: AI augments, not replaces)             │
│  - Are processes in place to manage AI lifecycle (experiment → production)?  │
│  - Have we addressed change management and employee concerns?                │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  CATEGORY 4: SYSTEMS & DATA READINESS                                        │
│  ─────────────────────────────────                                           │
│  • System Landscape (maps to #5 AI Platform & Technology Stack)              │
│  • Data Access (maps to #4 Data Strategy, accessibility section)             │
│  • Data Quality (maps to #4 Data Strategy, quality section)                  │
│                                                                               │
│  Key questions:                                                               │
│  - What is our tech stack? (Cloud, LLMs, vector DBs, orchestration)          │
│  - Is our data accessible? (APIs, dashboards, self-service)                  │
│  - Is our data quality sufficient? (Clean, labeled, bias-free)               │
│  - Do we have an AI flywheel? (Product generates data → improves AI)         │
│                                                                               │
└──────────────────────────────────────────────────────────────────────────────┘
```

**When to use 4-category view:**
- Compliance-heavy industries (finance, healthcare, government)
- Organizations new to AI (simpler framework to start)
- Presentations to non-technical executives (easier to digest)

**When to use 9-box view:**
- Startups/scale-ups (more granular, action-oriented)
- AI-mature organizations (need detail on platform, costs, etc.)
- Cross-functional teams (each box has a clear owner)

---

## Deloitte 4 Questions (GenAI Customer Strategy)

From [Deloitte AI-ready strategy](https://www.deloittedigital.com/us/en/insights/perspective/ai-ready-strategy.html):

```
┌──────────────────────────────────────────────────────────────────────────────┐
│             DELOITTE'S 4 CRITICAL QUESTIONS FOR AI READINESS                  │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  QUESTION 1: How can GenAI inform or validate your customer strategy?        │
│  ─────────────────────────────────────────────────────────────               │
│                                                                               │
│  Use AI to:                                                                   │
│  • Build smarter customer personas (analyze 10M+ interactions for patterns)  │
│  • Discover new segments (AI clusters customers by behavior, not demographics)│
│  • Deliver differentiated CX (personalization at scale, 1:1 experiences)     │
│                                                                               │
│  Example:                                                                     │
│  "We used AI to analyze 2M support tickets and discovered a new segment:     │
│   'Power Users' who ask 10x more questions but have 5x higher LTV. We        │
│   created a premium AI Concierge tier for them at +$50/month."               │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  QUESTION 2: Have you evaluated use cases for impact, feasibility, viability?│
│  ─────────────────────────────────────────────────────────────────────────   │
│                                                                               │
│  Before major investment, assess:                                             │
│  • IMPACT: Business value (revenue, cost, satisfaction)                      │
│  • FEASIBILITY: Technical complexity, data availability, talent              │
│  • VIABILITY: ROI, time-to-value, cost, risk                                 │
│                                                                               │
│  Framework:                                                                   │
│  Quick Wins: High impact + High feasibility → Do first (3-6 months)          │
│  Strategic Bets: High impact + Medium feasibility → Plan carefully (6-12mo)  │
│  Moonshots: High impact + Low feasibility → Explore, but don't commit yet    │
│  Low Priority: Low impact or Low viability → Kill or defer to future         │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  QUESTION 3: Do you have risk mitigation processes in place?                 │
│  ────────────────────────────────────────────────────────                    │
│                                                                               │
│  Critical risks to address:                                                   │
│  • Data security: Encrypted storage, access control, SOC 2 compliance        │
│  • Bias & fairness: Quarterly audits, demographic parity, mitigation plans   │
│  • Hallucinations: Confidence scores, human-in-loop, source attribution      │
│  • Governance: AI Steering Committee, ethics officer, model ownership        │
│  • Human oversight: Always allow escalation to human, override capability    │
│                                                                               │
│  Red flags (stop if missing):                                                 │
│  ❌ No one is accountable for AI ethics                                       │
│  ❌ No bias audits or fairness metrics                                        │
│  ❌ No human-in-loop for high-stakes decisions                                │
│  ❌ No incident response plan for AI failures                                 │
│                                                                               │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  QUESTION 4: How will you build trust and maintain ethical AI?               │
│  ──────────────────────────────────────────────────────────                  │
│                                                                               │
│  Trust pillars:                                                               │
│  • TRANSPARENCY: Explain AI decisions ("Why this answer?" feature)           │
│  • ETHICS: Responsible AI framework (fairness, privacy, safety)              │
│  • GOVERNANCE: Clear accountability, audit logs, version control             │
│  • DATA PROTOCOLS: PII scrubbing, GDPR compliance, data minimization         │
│  • CUSTOMER TRUST: Disclosure ("You're chatting with AI"), opt-out option    │
│                                                                               │
│  Customer-facing best practices:                                              │
│  ✓ Always disclose AI use upfront ("This is an AI assistant")                │
│  ✓ Provide confidence scores ("I'm 85% confident this answer is correct")    │
│  ✓ Allow human escalation ("Talk to a human" button always visible)          │
│  ✓ Explain decisions ("Here's why I recommended this product")               │
│  ✓ Honor opt-outs ("I'd prefer not to use AI" → route to human immediately)  │
│                                                                               │
└──────────────────────────────────────────────────────────────────────────────┘
```

**How to use Deloitte's 4 Questions:**
1. Use as a final validation after completing the 9-box canvas
2. If you can't confidently answer "yes" to all 4 → NOT READY, address gaps
3. Present to board/investors as proof of readiness

---

## Key Concepts Reference

### AI Flywheel

```
       ┌─────────────────────────────────┐
       │  1. PRODUCT GENERATES DATA      │
       │  (user interactions, feedback)  │
       └─────────────┬───────────────────┘
                     │
                     ▼
       ┌─────────────────────────────────┐
       │  2. AI ANALYZES DATA            │
       │  (finds patterns, trains models)│
       └─────────────┬───────────────────┘
                     │
                     ▼
       ┌─────────────────────────────────┐
       │  3. AI IMPROVES PRODUCT         │
       │  (better features, personalized)│
       └─────────────┬───────────────────┘
                     │
                     ▼
       ┌─────────────────────────────────┐
       │  4. ATTRACTS MORE CUSTOMERS     │
       │  (better product = more users)  │
       └─────────────┬───────────────────┘
                     │
                     ▼
       ┌─────────────────────────────────┐
       │  5. MORE DATA (repeat)          │
       │  Virtuous cycle continues       │
       └─────────────────────────────────┘

Example: Netflix
• Users watch shows (data: what you watch, when you pause, rewind)
• AI analyzes patterns (learns your taste, predicts what you'll like)
• AI improves product (better recommendations on homepage)
• Attracts more users (friends see your good recommendations, sign up)
• More data → better AI → repeat
```

### Zig-Zag Costs

AI costs don't follow traditional IT patterns (linear, predictable). They spike unpredictably:

```
COST
  │
  │       ╱╲ Launch spike (3x normal)
  │      ╱  ╲
  │     ╱    ╲ Optimization drop
  │    ╱      ╲___
  │   ╱           ╲___
  │  ╱                ╲___ Plateau (mature system)
  │ ╱
  │╱__________________________________________
  0   3   6   9   12  15  18  21  24  MONTHS

Why zig-zag?
• Spikes: Experimentation (trying 10 prompts to find the best one)
• Drops: Optimizations kick in (caching, smaller models, batching)
• Plateau: Mature system (predictable traffic, efficient inference)

Traditional IT costs (servers, licenses):
 ─────────────────────────────────────  (flat, predictable)

AI costs:
 ╱╲   ╱╲   ╱╲___  (spiky, then efficient)
```

### 3Es Framework (Success Metrics)

```
┌─────────────────────────────────────────────────────────────────┐
│  3Es: EFFICIENCY, EFFECTIVENESS, USER EXPERIENCE                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. EFFICIENCY (Do more with less)                               │
│  ───────────────────────────────                                │
│  • Cost per output (e.g., cost per ticket resolved)             │
│  • Time per task (e.g., time to answer customer question)       │
│  • Resource utilization (e.g., agent handles 3x tickets)        │
│                                                                  │
│  Example metrics:                                                │
│  • Support cost per ticket: $12 → $5 (58% improvement)           │
│  • Agent productivity: Handle 100 tickets/week → 300 tickets/week│
│  • Time to resolution: 4 hours → 15 minutes (94% faster)         │
│                                                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  2. EFFECTIVENESS (Better outcomes)                              │
│  ─────────────────────────────                                  │
│  • Accuracy (e.g., % of correct answers)                        │
│  • Quality (e.g., customer satisfaction with answer)            │
│  • Impact (e.g., did it solve the problem?)                     │
│                                                                  │
│  Example metrics:                                                │
│  • Answer accuracy: 78% → 90%+ (15% improvement)                 │
│  • First-contact resolution: 60% → 84% (40% improvement)         │
│  • Customer retention: 85% → 92% (8% improvement)                │
│                                                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  3. USER EXPERIENCE (Delightful interactions)                    │
│  ──────────────────────────────────────                         │
│  • Speed (e.g., wait time, response time)                       │
│  • Convenience (e.g., 24/7 availability, multilingual)          │
│  • Satisfaction (e.g., CSAT, NPS)                               │
│                                                                  │
│  Example metrics:                                                │
│  • Wait time: 4 hours → 15 minutes (94% reduction)               │
│  • Availability: 9-5 weekdays → 24/7 (300% increase)             │
│  • CSAT: 78% → 92% (18% improvement)                             │
│  • Multilingual: 1 language → 10 languages (instant translation)│
│                                                                  │
└─────────────────────────────────────────────────────────────────┘

Why 3Es matter:
• Efficiency alone is not enough (fast but wrong answers = bad)
• Effectiveness alone is not enough (correct but slow = frustrating)
• UX alone is not enough (delightful but expensive = unsustainable)

Ideal AI project improves ALL 3Es simultaneously.
```

---

**Template Source:** Incremental Excellence  
**Author:** Peter Scheffer  
**License:** CC BY-SA 4.0  
**URL:** incrementalexcellence.com/ai-readiness-canvas  
**Document Version:** 1.0  
**Last Updated:** February 10, 2026
